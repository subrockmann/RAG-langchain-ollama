{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import openai# from dotenv import load_dotenv, find_dotenv\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "\n",
    "#from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.llms import Ollama\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "from langchain.vectorstores import DeepLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "ACTIVELOOP_TOKEN = os.environ['ACTIVELOOP_TOKEN']\n",
    "ACTIVELOOP_USERNAME = os.environ['ACTIVELOOP_USERNAME']\n",
    "\n",
    "#my_activeloop_org_id = \"<YOUR-ACTIVELOOP-ORG-ID>\"\n",
    "my_activeloop_dataset_name = \"langchain_course_indexers_retrievers\"\n",
    "dataset_path = f\"hub://{ACTIVELOOP_USERNAME}/{my_activeloop_dataset_name}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_id = 'kb-material'# replace with your database name\n",
    "#DeepLake.force_delete_by_path(f\"hub://{ACTIVELOOP_USERNAME}/{db_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_model = \"gpt-3.5-turbo\"\n",
    "# chat_open = ChatOpenAI(temperature=0.0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_url = \"http://localhost:11434\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(base_url=local_url, model=\"mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The reason why the sky appears blue during a clear day is due to a natural phenomenon called Rayleigh scattering. When sunlight enters the Earth's atmosphere, it interacts with different gases and particles in the air. Blue light has a shorter wavelength than other colors in the visible spectrum, making it more likely to collide with and be scattered by molecules of nitrogen and oxygen in the atmosphere.\n",
      "\n",
      "As these blue light photons get scattered in all directions, they fill the sky with a scattering of blue hues, making the sky appear blue to our eyes when we look up. However, it's essential to note that the sky doesn't have a uniform blue color; instead, it varies from shades of baby blue near the horizon to a deeper, almost navy blue at the highest points in the sky. This happens due to how distance and air density affect the scattering process.\n"
     ]
    }
   ],
   "source": [
    "print(llm(\"Why is the sky blue?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Olaf Scholz ist ein deutscher Politiker. Er ist seit Dezember 2021 Bundeskanzler von Deutschland. Zuvor war er Finanzminister und Vizekanzler in der Regierung Merkel.\n"
     ]
    }
   ],
   "source": [
    "print(llm(\"Wer is Olaf Scholz? Bitte in Deutsch antworten\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama embeddings\n",
    "embeddings = OllamaEmbeddings(model=\"mistral\")\n",
    "# OpenAI embeddings\n",
    "#embedding = OpenAIEmbeddings()\n",
    "\n",
    "llm_open = Ollama(  model=\"mistral\",\n",
    "                    #model='Llama2',\n",
    "                    callback_manager = CallbackManager([StreamingStdOutCallbackHandler()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedding function is deprecated and will be removed in the future. Please use embedding instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://newinmunich/langchain_course_indexers_retrievers already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# text to write to a local file\n",
    "# taken from https://www.theverge.com/2023/3/14/23639313/google-ai-language-model-palm-api-challenge-openai\n",
    "text = \"\"\"Google opens up its AI language model PaLM to challenge OpenAI and GPT-3\n",
    "Google is offering developers access to one of its most advanced AI language models: PaLM.\n",
    "The search giant is launching an API for PaLM alongside a number of AI enterprise tools\n",
    "it says will help businesses “generate text, images, code, videos, audio, and more from\n",
    "simple natural language prompts.”\n",
    "\n",
    "PaLM is a large language model, or LLM, similar to the GPT series created by OpenAI or\n",
    "Meta’s LLaMA family of models. Google first announced PaLM in April 2022. Like other LLMs,\n",
    "PaLM is a flexible system that can potentially carry out all sorts of text generation and\n",
    "editing tasks. You could train PaLM to be a conversational chatbot like ChatGPT, for\n",
    "example, or you could use it for tasks like summarizing text or even writing code.\n",
    "(It’s similar to features Google also announced today for its Workspace apps like Google\n",
    "Docs and Gmail.)\n",
    "\"\"\"\n",
    "\n",
    "# write text to local file\n",
    "with open(\"my_file.txt\", \"w\") as file:\n",
    "    file.write(text)\n",
    "\n",
    "# use TextLoader to load text from local file\n",
    "loader = TextLoader(\"my_file.txt\")\n",
    "docs_from_file = loader.load()\n",
    "\n",
    "print(len(docs_from_file))\n",
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 373, which is longer than the specified 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# create a text splitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "\n",
    "# split documents into chunks\n",
    "docs = text_splitter.split_documents(docs_from_file)\n",
    "\n",
    "print(len(docs))\n",
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 2 embeddings in 1 batches of size 2:: 100%|██████████| 1/1 [00:16<00:00, 16.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://newinmunich/langchain_course_indexers_retrievers', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      "   text       text      (2, 1)      str     None   \n",
      " metadata     json      (2, 1)      str     None   \n",
      " embedding  embedding  (2, 4096)  float32   None   \n",
      "    id        text      (2, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['178ab390-c8ed-11ee-b55d-00155d0a12d7',\n",
       " '178ab430-c8ed-11ee-b55d-00155d0a12d7']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning srt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_srt_text(lines):  \n",
    "    text = ''\n",
    "    for line in lines:\n",
    "        if re.search('^[0-9]+$', line) is None and re.search('^[0-9]{2}:[0-9]{2}:[0-9]{2}', line) is None and re.search('^$', line) is None:\n",
    "            line = line.rstrip('\\n')\n",
    "            if line == \"\": \n",
    "                print(\"Empty line\")\n",
    "            else:\n",
    "                text = text+ \" \" + line\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11 - ND545 C1 L0 10 Lesson Recap - lang_en.srt', '5 - ND545 C1 L0 05 Cybersecurity And You Video - lang_en.srt', '3 - ND545 C1 L0 03 Lesson Outline Video - lang_en.srt', '2 - ND545 C1 L0 02 Course Outline Video - lang_en.srt', '1 - ND545 C1 L0 01 Meet Your Instructor Video - lang_en.srt', '7 - ND545 C1 L0 07 History Of Cybersecurity Video - lang_en.srt', '8 - ND545 C1 L0 08 Tools, Environment & Dependencies Pt 1 - lang_en.srt', '9 - ND545 C1 L0 08.1 Tools, Environment & Dependencies Pt 2 - lang_en.srt', '6 - Nd545-C1-L0-06-Business-Stakeholders-Video V2 - lang_en.srt', '4 - ND545 C1 L0 04 Introduction To Cybersecurity Video - lang_en.srt', '10 - ND545 C1 L0 09 Project- Cybersecurity Fundamentals Video - lang_en.srt']\n"
     ]
    }
   ],
   "source": [
    "def get_filenames_in_directory(directory):\n",
    "    filenames = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if os.path.isfile(os.path.join(directory, filename)):\n",
    "            filenames.append(filename)\n",
    "    return filenames\n",
    "\n",
    "# Example usage:\n",
    "source_directory = \"./data/raw/\"\n",
    "target_directory = \"./data/clean\"\n",
    "\n",
    "\n",
    "filenames = get_filenames_in_directory(source_directory)\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_extension = \"srt\"\n",
    "new_extension = \"txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_modified_filename(filename, directory, old_extension, new_extension):\n",
    "\n",
    "    if filename.endswith(old_extension):\n",
    "        old_path = os.path.join(directory, filename)\n",
    "        new_filename = filename.rsplit(\".\", 1)[0] + \".\" + new_extension\n",
    "        #new_path = os.path.join(directory, new_filename)\n",
    "    return new_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 - ND545 C1 L0 10 Lesson Recap - lang_en.txt\n",
      "5 - ND545 C1 L0 05 Cybersecurity And You Video - lang_en.txt\n",
      "3 - ND545 C1 L0 03 Lesson Outline Video - lang_en.txt\n",
      "2 - ND545 C1 L0 02 Course Outline Video - lang_en.txt\n",
      "1 - ND545 C1 L0 01 Meet Your Instructor Video - lang_en.txt\n",
      "7 - ND545 C1 L0 07 History Of Cybersecurity Video - lang_en.txt\n",
      "8 - ND545 C1 L0 08 Tools, Environment & Dependencies Pt 1 - lang_en.txt\n",
      "9 - ND545 C1 L0 08.1 Tools, Environment & Dependencies Pt 2 - lang_en.txt\n",
      "6 - Nd545-C1-L0-06-Business-Stakeholders-Video V2 - lang_en.txt\n",
      "4 - ND545 C1 L0 04 Introduction To Cybersecurity Video - lang_en.txt\n",
      "10 - ND545 C1 L0 09 Project- Cybersecurity Fundamentals Video - lang_en.txt\n"
     ]
    }
   ],
   "source": [
    "for filename in filenames:\n",
    "    print(create_modified_filename(filename, source_directory, old_extension, new_extension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_txt_from_srt(source_directory, target_directory, old_extention=\"srt\", new_extension=\"txt\"):\n",
    "    filenames = get_filenames_in_directory(source_directory)\n",
    "    if not os.path.exists(target_directory):\n",
    "        os.makedirs(target_directory)\n",
    "    for filename in filenames:\n",
    "        \n",
    "        with open(os.path.join(source_directory, filename), 'r', encoding='utf8') as f:\n",
    "            lines = f.readlines()\n",
    "        new_filename = create_modified_filename(filename, source_directory, old_extension, new_extension)\n",
    "        clean_text = clean_srt_text(lines)\n",
    "\n",
    "        new_file_path = os.path.join(target_directory, new_filename)\n",
    "        with open(new_file_path, 'w') as f:\n",
    "            f.write(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_txt_from_srt(source_directory, target_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 113.65it/s]\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader(target_directory, glob=\"**/*.txt\", show_progress=True)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
